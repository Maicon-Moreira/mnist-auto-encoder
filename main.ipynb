{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600260561392",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('mnist_train.csv', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    data = list(reader)\n",
    "\n",
    "data = data[1:]\n",
    "data = [a[1:] for a in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xs = np.array(data).reshape((60000, 28, 28, 1)).astype(int)/255\n",
    "ys = xs\n",
    "\n",
    "print(xs.shape)\n",
    "print(ys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./xs','wb') as f: pickle.dump(xs, f)\n",
    "with open('./ys','wb') as f: pickle.dump(ys, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l = tf.keras.layers\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    l.Conv2D(filters=4, kernel_size=3, padding='valid', input_shape=(28, 28, 1)),\n",
    "    l.Conv2D(filters=2, kernel_size=3, padding='valid'),\n",
    "    l.Conv2D(filters=1, kernel_size=3, padding='valid'),\n",
    "    l.Conv2D(filters=1, kernel_size=3, padding='valid'),\n",
    "\n",
    "    l.Flatten(),\n",
    "\n",
    "    l.Dense(100, activation='relu'),\n",
    "    l.Dropout(0.3),\n",
    "\n",
    "\n",
    "    l.Dense(2, activation='tanh'),\n",
    "\n",
    "\n",
    "    l.Dense(100, activation='relu'),\n",
    "    l.Dropout(0.3),\n",
    "\n",
    "    l.Dense(20*20*4, activation='relu'),\n",
    "    l.Reshape((20, 20, 4)),\n",
    "\n",
    "    l.Conv2DTranspose(filters=4, kernel_size=3, padding='valid'),\n",
    "    l.Conv2DTranspose(filters=2, kernel_size=3, padding='valid'),\n",
    "    l.Conv2DTranspose(filters=1, kernel_size=3, padding='valid'),\n",
    "    l.Conv2DTranspose(filters=1, kernel_size=3, padding='valid')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(xs[1])\n",
    "plt.show()\n",
    "\n",
    "x = np.array([xs[1]])\n",
    "plt.imshow(model.predict(x)[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l = tf.keras.layers\n",
    "\n",
    "encoder = tf.keras.models.Sequential([\n",
    "    l.Conv2D(filters=4, kernel_size=3, padding='valid', input_shape=(28, 28, 1)),\n",
    "    l.Conv2D(filters=2, kernel_size=3, padding='valid'),\n",
    "    l.Conv2D(filters=1, kernel_size=3, padding='valid'),\n",
    "    l.Conv2D(filters=1, kernel_size=3, padding='valid'),\n",
    "\n",
    "    l.Flatten(),\n",
    "\n",
    "    l.Dense(100, activation='relu'),\n",
    "    l.Dropout(0.3),\n",
    "\n",
    "\n",
    "    l.Dense(2, activation='tanh')\n",
    "])\n",
    "\n",
    "encoder.summary()\n",
    "\n",
    "for i in range(8):\n",
    "    encoder.layers[i].set_weights(model.layers[i].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out = encoder.predict(xs[:500]).reshape(2, 500)\n",
    "\n",
    "plt.scatter(out[0],out[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l = tf.keras.layers\n",
    "\n",
    "decoder = tf.keras.models.Sequential([\n",
    "    l.Dense(100, activation='relu', input_shape=(2,)),\n",
    "    l.Dropout(0.3),\n",
    "\n",
    "    l.Dense(20*20*4, activation='relu'),\n",
    "    l.Reshape((20, 20, 4)),\n",
    "\n",
    "    l.Conv2DTranspose(filters=4, kernel_size=3, padding='valid'),\n",
    "    l.Conv2DTranspose(filters=2, kernel_size=3, padding='valid'),\n",
    "    l.Conv2DTranspose(filters=1, kernel_size=3, padding='valid'),\n",
    "    l.Conv2DTranspose(filters=1, kernel_size=3, padding='valid')\n",
    "])\n",
    "\n",
    "decoder.summary()\n",
    "\n",
    "for i in range(8):\n",
    "    decoder.layers[i].set_weights(model.layers[i+8].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = decoder.predict(np.array([[-1, -0.5]]))[0]\n",
    "\n",
    "plt.imshow(out)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "final_img = Image.new('RGB', (4000, 4000), color='black')\n",
    "\n",
    "\n",
    "for i in tqdm(range(5000)):\n",
    "    # i = int(np.random.random()*60000)\n",
    "\n",
    "    prediction = encoder.predict(np.array([xs[i]]))[0]\n",
    "    prediction = (prediction + 1)/2\n",
    "    prediction = prediction*4000\n",
    "    prediction = np.uint32(prediction)\n",
    "\n",
    "    img = [[[xs[i][y][x],xs[i][y][x],xs[i][y][x]] for x in range(28)] for y in range(28)]\n",
    "    img = np.array(img)\n",
    "    img = img.reshape((28,28,3))\n",
    "    img = np.uint8(255 - img*255)\n",
    "    img = Image.fromarray(img)\n",
    "    img = img.resize((100,100))\n",
    "\n",
    "\n",
    "    final_img.paste(img, (prediction[0],prediction[1]))\n",
    "\n",
    "\n",
    "\n",
    "final_img.save('./final_img.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "\n  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 4704 into shape (28,28,3)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-4b5bca8c6642>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 4704 into shape (28,28,3)"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "final_img = Image.new('RGB', (4000, 4000), color='black')\n",
    "\n",
    "\n",
    "for x in tqdm(range(40)):\n",
    "    for y in range(40):\n",
    "        X = np.array([[(x-20)/20,(y-20)/20]])\n",
    "\n",
    "\n",
    "        prediction = decoder.predict(X)[0]\n",
    "        prediction = np.clip(prediction, 0, 1)\n",
    "        print(prediction)\n",
    "\n",
    "        img = [[[prediction[y][x],prediction[y][x],prediction[y][x]] for x in range(28)] for y in range(28)]\n",
    "        img = np.array(img)\n",
    "        img = img.reshape((28,28,3))\n",
    "        img = np.uint8(255 - img*255)\n",
    "        img = Image.fromarray(img)\n",
    "        img = img.resize((100,100))\n",
    "\n",
    "\n",
    "        final_img.paste(img, (x*100,y*100))\n",
    "\n",
    "\n",
    "\n",
    "final_img.save('./final_img2.jpg')"
   ]
  }
 ]
}